#!/usr/bin/env python
import argparse
import logging
import os
import signal
import sys
from subprocess import call

from ghtools.WorkList import WorkList

logger = logging.getLogger()
logger.addHandler(logging.StreamHandler())
logger.setLevel(logging.INFO)

def signal_handler(signal, frame):
    os._exit(0)

signal.signal(signal.SIGINT, signal_handler)

def process_script_arguments(args):
    parser = argparse.ArgumentParser(description='Analyze GitHub repositories')
    parser.add_argument('-f', '--force', action='store_true',
                        help='also run for failed repositories')
    parser.add_argument('-i', '--infile', type=argparse.FileType('r+'),
                        help='read list of repositories from this JSON file')
    parser.add_argument('command',
                        help='command to execute for each repository')
    if len(args) < 2:
        parser.print_help()
        sys.exit(1)
    result = parser.parse_args()
    return result

if __name__ == "__main__":
    args = process_script_arguments(sys.argv)
    if args.infile is not None:
        wl = WorkList(args.infile)
    else:
        wl = WorkList()

    for repo in wl:
        if not repo.is_status_ok() and not args.force:
            logger.info('Skipping id ' + str(repo['id']))
            continue
        if not 'working_directory' in repo:
            logger.error('No working directory found for system' +
                         repo['name'])
        try:
            call([args.command, repo['working_directory']])
        except OSError as e:
            logger.error('Command failed: ' + str(e))
            repo.set_status_failed()

    if args.infile is None:
        wl.write(sys.stdout)
