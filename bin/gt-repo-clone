#!/usr/bin/env python
import argparse
import logging
import os
import signal
import sys

from sh import git

from ghtools.WorkList import WorkList

logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)
logger.addHandler(logging.StreamHandler())


def signal_handler(signal, frame):
    os._exit(0)


signal.signal(signal.SIGINT, signal_handler)


def clone_repository(repo, root_directory):
    system = repo['id'] + '-' + repo['name']
    if 'working_directory' in repo:
        target_dir = repo['working_directory']
    else:
        target_dir = os.path.join(root_directory, system)
    if os.path.isdir(target_dir):
        logger.info('Found existing working directory, skipping ' + system)
        repo['working_directory'] = target_dir
        return
    try:
        logger.info("Shallow cloning repository for project: " +
                    repo['name'] + "...")
        git.clone("--depth=1", repo['url'] + '.git', target_dir)
        repo['working_directory'] = target_dir
    except:
        logger.error('Error in downloading codebase: ' + repo['name'])
        logger.error(sys.exc_info())
        logger.error('On line: ' + format(sys.exc_info()[-1].tb_lineno))
        repo.set_status_failed()


def process_script_arguments():
    parser = argparse.ArgumentParser(description='Clone GitHub repositories')
    parser.add_argument('-i', '--infile', type=argparse.FileType('r'),
                        help='read list of repositories from this JSON file')
    parser.add_argument('destination', metavar='destination directory',
                        help='destination directory for cloned repositories')
    args = parser.parse_args()

    if not os.path.isdir(args.destination):
        parser.print_help()
        sys.exit()

    return args


if __name__ == "__main__":
    args = process_script_arguments()
    if args.infile is not None:
        wl = WorkList(args.infile)
    else:
        wl = WorkList()

    for repo in wl:
        clone_repository(repo, args.destination)

    wl.write(sys.stdout)
